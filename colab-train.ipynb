{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of training_jupyter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulowe/ml-lambda/blob/main/colab-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swXGJ1Hn5Ha6"
      },
      "source": [
        "## Import packages \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpRqdf73J_W",
        "outputId": "331db52e-71bd-4b03-a20c-66e113e4e2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv as csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEFUPItd4-Ot"
      },
      "source": [
        "- Verify you are running Version 0.23.1 of sklearn. Some of the packages used for model evaluation only work with this version or higher.\n",
        "\n",
        "- Run <> to upgrade sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ9o75PJ3J_e",
        "outputId": "42897be6-e907-4228-d090-43eec0b50dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "sklearn.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.22.2.post1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAEVz-ab52Tp"
      },
      "source": [
        "## Import Data\n",
        "\n",
        "X - all training examples\n",
        "y - all true labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWeab8wQ3J_j"
      },
      "source": [
        "data = pd.read_csv('./syntheticData.csv')\n",
        "X, y = data.iloc[:, 1:], data.iloc[:,0]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS1m9EoR9r4n"
      },
      "source": [
        "## Visualize Data \n",
        "\n",
        "(80100 * 377) training matrix\n",
        "\n",
        "(801 * 1) label vector\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXtjJlpf95_C",
        "outputId": "24edf4ae-5262-430a-d358-cd2ae056e4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(X.head())\n",
        "print(X.shape)\n",
        "print(y.head())\n",
        "print(y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Abdominal distention  ...  Wrist weakness\n",
            "0                     0  ...               0\n",
            "1                     0  ...               0\n",
            "2                     0  ...               0\n",
            "3                     0  ...               0\n",
            "4                     0  ...               0\n",
            "\n",
            "[5 rows x 377 columns]\n",
            "(80100, 377)\n",
            "0    Abdominal aortic aneurysm\n",
            "1    Abdominal aortic aneurysm\n",
            "2    Abdominal aortic aneurysm\n",
            "3    Abdominal aortic aneurysm\n",
            "4    Abdominal aortic aneurysm\n",
            "Name: Conditions_name, dtype: object\n",
            "(80100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPFZnpeQ_Vyg"
      },
      "source": [
        "## Split into training, cross validation and test sets\n",
        "\n",
        "- Shuffle dataset\n",
        "\n",
        "- Perform Split (60-20-20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzLuuwlO3J_n",
        "outputId": "53d9da82-c281-490e-f195-c5c2c7868929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, stratify=y)\n",
        "\n",
        "X_cv, X_test, y_cv, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
        "\n",
        "print(\"Training data dimensions\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Cross validation data dimensions\")\n",
        "print(X_cv.shape)\n",
        "print(y_cv.shape)\n",
        "\n",
        "print(\"Test data dimensions\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data dimensions\n",
            "(48060, 377)\n",
            "(48060,)\n",
            "Cross validation data dimensions\n",
            "(16020, 377)\n",
            "(16020,)\n",
            "Test data dimensions\n",
            "(16020, 377)\n",
            "(16020,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX9U7cLFE-0S"
      },
      "source": [
        "## Train default MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OvUBtp1E9GO",
        "outputId": "d47a958c-7e46-4946-9f5b-abcf51c075c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "clf = MLPClassifier()\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoNEvTPKeSBO"
      },
      "source": [
        "## Training Variant: Bottom Up implementation\n",
        "\n",
        "In this variant I will implement an identical classifier to the one we trained above. The objective here is to expose underlying components of the training process and perform direct optimization and monitoring techniques.\n",
        "\n",
        "- Sigmoid\n",
        "- Random initialization for weights\n",
        "- Feedforward Propagation - Prediction function\n",
        "- Neural Network Cost Function\n",
        "- Backpropagation\n",
        "- Sigmoid Gradient\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGkv5Fw4CvWe"
      },
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    return the sigmoid of z\n",
        "    \"\"\"\n",
        "    \n",
        "    return 1/ (1 + np.exp(-z))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGkxaGWV5JNg"
      },
      "source": [
        "### Random initialization\n",
        "Select values for $\\Theta^{(l)}$ uniformly in the range $[-\\epsilon_{init} , \\epsilon_{init}]$\n",
        "One effective strategy for choosing $\\epsilon_{init}$ is to base it on the number of units in the network\n",
        "$\\epsilon_{init} = \\frac{\\sqrt{6}}{\\sqrt{L_{in} + L_{out}}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN65BZjM4wiQ"
      },
      "source": [
        "def randInitializeWeights(L_in, L_out):\n",
        "    \"\"\"\n",
        "    randomly initializes the weights of a layer with L_in incoming connections and L_out outgoing connections.\n",
        "    \"\"\"\n",
        "    \n",
        "    epi = (6**1/2) / (L_in + L_out)**1/2\n",
        "    \n",
        "    W = np.random.rand(L_out,L_in +1) *(2*epi) -epi\n",
        "    \n",
        "    return W"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AytG6WWq5yi8"
      },
      "source": [
        "Initialize Theta Vectors\n",
        "\n",
        "Here we will randomly intialize theta vecotrs for each layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h0PA0zZ6GKu"
      },
      "source": [
        "input_layer_size  = 377\n",
        "hidden_layer_size = 25\n",
        "num_labels = 801\n",
        "\n",
        "Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "nn_params = np.append(Theta1.flatten(),Theta2.flatten())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ6naexnBlEC",
        "outputId": "c6cd9f17-5fb2-4795-9575-81b70db6325c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(Theta1.shape)\n",
        "print(Theta2.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25, 378)\n",
            "(801, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpulXfEm29u5"
      },
      "source": [
        "def sigmoidGradient(z):\n",
        "    \"\"\"\n",
        "    computes the gradient of the sigmoid function\n",
        "    \"\"\"\n",
        "    sigmoid = 1/(1 + np.exp(-z))\n",
        "    \n",
        "    return sigmoid *(1-sigmoid)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfwpjsrqfAFf"
      },
      "source": [
        "def predict(Theta1, Theta2, X):\n",
        "    \"\"\"\n",
        "    Predict the label of an input given a trained neural network\n",
        "    \"\"\"\n",
        "    m= X.shape[0]\n",
        "    X = np.hstack((np.ones((m,1)),X))\n",
        "    \n",
        "    a1 = sigmoid(X @ Theta1.T)\n",
        "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
        "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
        "    \n",
        "    #find out why its +1\n",
        "    return np.argmax(a2,axis=1)+1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fdag_Ncm-lz",
        "outputId": "55fe76f5-79ef-4fa1-abe7-48501886f2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred = predict(Theta1, Theta2, X_train)\n",
        "# numEx - is the number of examples in the training set\n",
        "numEx = 48060\n",
        "\n",
        "print(\"Training Set Accuracy:\",sum(pred[:,np.newaxis]==y_train.to_numpy)[0]/numEx*100,\"%\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFxEC4tGo8je"
      },
      "source": [
        "## Computing Neural Network Cost function\n",
        "\n",
        "$J(\\Theta) = \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^k [-y_k^{(i)} log(h_\\Theta(x^{(i)})_k) - ( 1 -y_k^{(i)} log (1-h_\\Theta(x^{(i)})_k)] + \\frac{\\lambda}{2m}[\\sum_{j=1}^{25} \\sum_{k=1}^{400} (\\Theta_{j,k}^{(1)})^2 + \\sum_{j=1}^{10} \\sum_{k=1}^{25} (\\Theta_{j,k}^{(2)})^2]$\n",
        "\n",
        "## Computing Backpropagation\n",
        "\n",
        "Implementation of Backpropagation to compute gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZOaGFiipJks"
      },
      "source": [
        "def nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda):\n",
        "    \"\"\"\n",
        "    nn_params contains the parameters unrolled into a vector\n",
        "    \n",
        "    compute the cost and gradient of the neural network\n",
        "    \"\"\"\n",
        "    # Reshape nn_params back into the parameters Theta1 and Theta2\n",
        "    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "    Theta2 = nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
        "    \n",
        "    m = X.shape[0]\n",
        "    J=0\n",
        "    X = np.hstack((np.ones((m,1)),X))\n",
        "    one_hot_y = np.zeros((m,num_labels))\n",
        "    \n",
        "    #a1 - activation from input layer -> layer 2\n",
        "    a1 = sigmoid(X @ Theta1.T)\n",
        "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
        "\n",
        "    #a2 - activation from layer 2 -> h_theta or L\n",
        "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
        "\n",
        "    \n",
        "    #Recoding the string labels as one hot matrix (#examples x #classes)\n",
        "\n",
        "    for i in range(1,num_labels+1):\n",
        "        one_hot_y[:,i-1][:,np.newaxis] = np.where(y==i,1,0)\n",
        "\n",
        "    #continuing with inner sum of cost function\n",
        "    for j in range(num_labels):\n",
        "        J = J + sum(-one_hot_y[:,j] * np.log(a2[:,j]) - (1-one_hot_y[:,j])*np.log(1-a2[:,j]))\n",
        "    \n",
        "    cost = 1/m* J\n",
        "    reg_J = cost + Lambda/(2*m) * (np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))\n",
        "    \n",
        "    # Implement the backpropagation algorithm to compute the gradients\n",
        "    \n",
        "    grad1 = np.zeros((Theta1.shape))\n",
        "    grad2 = np.zeros((Theta2.shape))\n",
        "    \n",
        "    for i in range(m):\n",
        "        xi= X[i,:] # 1 X 401\n",
        "        a1i = a1[i,:] # 1 X 26\n",
        "        a2i =a2[i,:] # 1 X 10\n",
        "        d2 = a2i - one_hot_y[i,:]\n",
        "        d1 = Theta2.T @ d2.T * sigmoidGradient(np.hstack((1,xi @ Theta1.T)))\n",
        "        grad1= grad1 + d1[1:][:,np.newaxis] @ xi[:,np.newaxis].T\n",
        "        grad2 = grad2 + d2.T[:,np.newaxis] @ a1i[:,np.newaxis].T\n",
        "        \n",
        "    grad1 = 1/m * grad1\n",
        "    grad2 = 1/m*grad2\n",
        "    \n",
        "    grad1_reg = grad1 + (Lambda/m) * np.hstack((np.zeros((Theta1.shape[0],1)),Theta1[:,1:]))\n",
        "    grad2_reg = grad2 + (Lambda/m) * np.hstack((np.zeros((Theta2.shape[0],1)),Theta2[:,1:]))\n",
        "    \n",
        "    return cost, grad1, grad2,reg_J, grad1_reg,grad2_reg\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o1Q-PqT3Oz_"
      },
      "source": [
        "def sigmoidGradient(z):\n",
        "    \"\"\"\n",
        "    computes the gradient of the sigmoid function\n",
        "    \"\"\"\n",
        "    sigmoid = 1/(1 + np.exp(-z))\n",
        "    \n",
        "    return sigmoid *(1-sigmoid)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHgUCRGK3f3N"
      },
      "source": [
        "## Computing the Cost Function (Non regularized and Regularized)\n",
        "\n",
        "Piece up different components defined above to compute cost of our Neural Network (regularized and unregularized)\n",
        "\n",
        "\n",
        "\n",
        "Hypothesizing an underfitted model because of Neural net architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RS6p_9W3th1",
        "outputId": "d1f800f3-4eff-450b-9ea1-139aa0014eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "J,reg_J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X_train, y_train.to_numpy, 1)[0:4:3]\n",
        "print(\"Cost at parameters (non-regularized):\",J,\"\\nCost at parameters (Regularized):\",reg_J)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost at parameters (non-regularized): 555.2204717326046 \n",
            "Cost at parameters (Regularized): 555.2204724099292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfkWlhEVF9tU"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Model Evaluation is an important part of understanding your model performance. \n",
        "\n",
        "For that matter it is crucial to choose a good evaluation metric you can monitor. In our case Accuracy makes the most sense.\n",
        "\n",
        "We will monitor\n",
        "\n",
        "- Accuracy on Test (clf)\n",
        "- AUC (implementation requires sklearn v0.23.1 +) \n",
        "\n",
        "- Accuracy on Test (eng)\n",
        "- AUC\n",
        "\n",
        "- Accuracy other vairants (vnt)\n",
        "- AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh2NvNnN3J_q",
        "outputId": "2ebafd59-94f3-44e3-856b-be5e002c194f",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "# Accuracy\n",
        "testsetPred = clf.predict(X_test)\n",
        "accuracy_score(y_test, testsetPred)\n",
        "\n",
        "#AUC\n",
        "#roc_auc_score(y_test, testsetPred, multi_class='ovr')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8111111111111111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sor71VKxFvpP"
      },
      "source": [
        "## Serialize Model Variant\n",
        "\n",
        "Serialize the classifier you like \n",
        "\n",
        "(1) Default Sklearn Model (clf)\n",
        "\n",
        "(2) Variant 1 (eng)\n",
        "\n",
        "(3) Variant 2\n",
        "\n",
        "(4) Variant 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n-32p1xFuv8"
      },
      "source": [
        "\"\"\"\n",
        "Serialize Model\n",
        "\"\"\"\n",
        "joblib.dump(clf, 'mlp.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}